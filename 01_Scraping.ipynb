{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spotipy\n",
    "import time\n",
    "from spotipy.oauth2 import SpotifyClientCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify's Authorizationn Flow via spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = '08ee90c081644cafa2db21e4f124fc53'\n",
    "c_secret = '8ba7fd8531484cddb405c20ffa78f647'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: You're using 'as_dict = True'.get_access_token will return the token string directly in future versions. Please adjust your code accordingly, or use get_cached_token instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=c_secret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
    "\n",
    "token = client_credentials_manager.get_access_token()\n",
    "spotify = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spotify's Web API allows for 50 searches per query. Each query has a max offset offset of 2,000.   \n",
    "The below scrape query grabs the top 2,000 tracks by year between 1970 - 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrying ...3secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1970 have been scraped successfully...\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "2,000 tracks from 1971 have been scraped successfully...\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1972 have been scraped successfully...\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1973 have been scraped successfully...\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1974 have been scraped successfully...\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1975 have been scraped successfully...\n",
      "retrying ...2secs\n",
      "retrying ...2secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1976 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1977 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1978 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1979 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1980 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1981 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1982 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1983 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1984 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1985 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1986 have been scraped successfully...\n",
      "retrying ...1secs\n",
      "2,000 tracks from 1987 have been scraped successfully...\n",
      "2,000 tracks from 1988 have been scraped successfully...\n",
      "2,000 tracks from 1989 have been scraped successfully...\n",
      "2,000 tracks from 1990 have been scraped successfully...\n",
      "2,000 tracks from 1991 have been scraped successfully...\n",
      "2,000 tracks from 1992 have been scraped successfully...\n",
      "2,000 tracks from 1993 have been scraped successfully...\n",
      "2,000 tracks from 1994 have been scraped successfully...\n",
      "2,000 tracks from 1995 have been scraped successfully...\n",
      "2,000 tracks from 1996 have been scraped successfully...\n",
      "2,000 tracks from 1997 have been scraped successfully...\n",
      "2,000 tracks from 1998 have been scraped successfully...\n",
      "2,000 tracks from 1999 have been scraped successfully...\n",
      "2,000 tracks from 2000 have been scraped successfully...\n",
      "2,000 tracks from 2001 have been scraped successfully...\n",
      "2,000 tracks from 2002 have been scraped successfully...\n",
      "2,000 tracks from 2003 have been scraped successfully...\n",
      "2,000 tracks from 2004 have been scraped successfully...\n",
      "2,000 tracks from 2005 have been scraped successfully...\n",
      "2,000 tracks from 2006 have been scraped successfully...\n",
      "2,000 tracks from 2007 have been scraped successfully...\n",
      "2,000 tracks from 2008 have been scraped successfully...\n",
      "2,000 tracks from 2009 have been scraped successfully...\n",
      "2,000 tracks from 2010 have been scraped successfully...\n",
      "2,000 tracks from 2011 have been scraped successfully...\n",
      "2,000 tracks from 2012 have been scraped successfully...\n",
      "2,000 tracks from 2013 have been scraped successfully...\n",
      "2,000 tracks from 2014 have been scraped successfully...\n",
      "2,000 tracks from 2015 have been scraped successfully...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendan/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,000 tracks from 2016 have been scraped successfully...\n",
      "2,000 tracks from 2017 have been scraped successfully...\n",
      "2,000 tracks from 2018 have been scraped successfully...\n",
      "2,000 tracks from 2019 have been scraped successfully...\n",
      "2,000 tracks from 2020 have been scraped successfully...\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for year in range(1970, 2021):\n",
    "    for i in range(-1, 2000, 50):\n",
    "        try:\n",
    "            tracks_data = sp.search(q='year:' + str(year), type = 'track', offset = i, limit =50)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        for x in range(len(tracks_data['tracks']['items'])):\n",
    "            audio_features = sp.audio_features(tracks_data['tracks']['items'][x]['uri'])\n",
    "            features_df = pd.DataFrame.from_dict(audio_features)\n",
    "            features_df['track_name'] = tracks_data['tracks']['items'][x]['name']\n",
    "            features_df['artist_name'] = tracks_data['tracks']['items'][x]['artists'][0]['name']\n",
    "            features_df['popularity'] = tracks_data['tracks']['items'][x]['popularity']\n",
    "            features_df['year'] = year\n",
    "            df = pd.concat([df, features_df], ignore_index=True)\n",
    "\n",
    "    print(f'2,000 tracks from {year} have been scraped successfully...')\n",
    "\n",
    "df.to_csv('./Data/1970-2020_tracks', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the scraped worked; mostly looking for duplicates..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104550, 23)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    102000\n",
       "True       2550\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80325"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['track_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([    'acousticness',     'analysis_url',      'artist_name',\n",
       "           'danceability',      'duration_ms',           'energy',\n",
       "                     'id', 'instrumentalness',              'key',\n",
       "               'liveness',         'loudness',             'mode',\n",
       "             'popularity',      'speechiness',            'tempo',\n",
       "         'time_signature',       'track_href',       'track_name',\n",
       "                   'type',              'uri',          'valence',\n",
       "                   'year',                  0],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99448"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['uri'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5101"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['uri'].duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
